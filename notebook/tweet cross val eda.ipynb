{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperatePunct(incomingString):\n",
    "    outstr = ''\n",
    "    characters = set(['!','@','#','$',\"%\",\"^\",\"&\",\"*\",\":\",\"\\\\\",\n",
    "                  \"(\",\")\",\"+\",\"=\",\"?\",\"\\'\",\"\\\"\",\";\",\"/\",\n",
    "                  \"{\",\"}\",\"[\",\"]\",\"<\",\">\",\"~\",\"`\",\"|\"])\n",
    "\n",
    "    for char in incomingString:\n",
    "        if char in characters:\n",
    "            outstr = outstr + ' ' + char + ' '\n",
    "        else:\n",
    "            outstr = outstr + char\n",
    "\n",
    "    return outstr\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "     return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def text_cleaner(wordList):\n",
    "    '''\n",
    "    INPUT: List of words to be tokenized\n",
    "    OUTPUT: List of tokenized words\n",
    "    '''\n",
    "\n",
    "    tokenziedList = []\n",
    "\n",
    "    for word in wordList:\n",
    "\n",
    "        #remove these substrings from the word\n",
    "        word = word.replace('[deleted]','')\n",
    "        word = word.replace('&gt','')\n",
    "\n",
    "        #if link, replace with linktag\n",
    "        if 'http' in word:\n",
    "            tokenziedList.append('LINK_TAG')\n",
    "            continue\n",
    "\n",
    "        #if reference to subreddit, replace with reddittag\n",
    "        if '/r/' in word:\n",
    "            tokenziedList.append('SUBREDDIT_TAG')\n",
    "            continue\n",
    "\n",
    "        #if reference to reddit user, replace with usertag\n",
    "        if '/u/' in word:\n",
    "            tokenziedList.append('USER_TAG')\n",
    "            continue\n",
    "\n",
    "        #if number, replace with numtag\n",
    "        #m8 is a word, 5'10\" and 54-59, 56:48 are numbers\n",
    "        if hasNumbers(word) and not any(char.isalpha() for char in word):\n",
    "            tokenziedList.append('NUM_TAG')\n",
    "            continue\n",
    "\n",
    "        #seperate puncuations and add to tokenizedList\n",
    "        newwords = seperatePunct(word).split(\" \")\n",
    "        tokenziedList.extend(newwords)\n",
    "\n",
    "    return tokenziedList\n",
    "\n",
    "def mytokenizer(comment):\n",
    "    '''\n",
    "    Input: takes in a reddit comment as a str or unicode and tokenizes it\n",
    "    Output: a tokenized list\n",
    "    '''\n",
    "\n",
    "    sentenceList = tokenizer.tokenize(comment)\n",
    "    wordList = []\n",
    "    for sentence in sentenceList:\n",
    "        wordList.extend(sentence.split(\" \"))\n",
    "\n",
    "    return text_cleaner(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path1 = '../../data/labeledRedditComments2.p'\n",
    "path2 = '../../data/twitter_cross_val.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['tokenize'] = df.tweet_text.map(lambda x: mytokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for row in xrange(len(df.index)):\n",
    "#     print df['tweet_text'].loc[row]\n",
    "# #     print df['tokenize'].loc[row]\n",
    "#     print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "    if '#' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['hashtag'] = df['tweet_text'].map(lambda x: myfunc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for row in xrange(len(df.index)):\n",
    "#     if df['hashtag'].loc[row]:\n",
    "#         print df['tweet_text'].loc[row]\n",
    "#         print df['tokenize'].loc[row]\n",
    "#         print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hashtag'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12168</td>\n",
       "      <td>I love how Jayden acts like we have no right t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13497</td>\n",
       "      <td>I been POPPIN since kindergarten nigga you a l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10058</td>\n",
       "      <td>Like a real life mean person could make you cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4559</td>\n",
       "      <td>Which fags are getting down and tributing Xmas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5514</td>\n",
       "      <td>From last night...my thoughts on J-Up and what...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         tweet_text  label\n",
       "0       12168  I love how Jayden acts like we have no right t...      1\n",
       "1       13497  I been POPPIN since kindergarten nigga you a l...      1\n",
       "2       10058  Like a real life mean person could make you cr...      0\n",
       "3        4559  Which fags are getting down and tributing Xmas...      1\n",
       "4        5514  From last night...my thoughts on J-Up and what...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
