{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "import cPickle as pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize\n",
    "from nltk.stem import snowball\n",
    "stemmer = snowball.SnowballStemmer(\"english\")\n",
    "from scipy import sparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# map labels from {-1, 1} to {0, 1}\n",
    "labels, y = np.unique(y, return_inverse=True)\n",
    "\n",
    "X_train, X_test = X[:2000], X[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65184641,  0.34815356],\n",
       "       [ 0.74603701,  0.25396299],\n",
       "       [ 0.32435191,  0.67564809],\n",
       "       ..., \n",
       "       [ 0.71962714,  0.28037286],\n",
       "       [ 0.08567679,  0.91432321],\n",
       "       [ 0.01836032,  0.98163968]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    '''\n",
    "    Load data into a data frame for use in running model\n",
    "    '''\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    '''Stem the tokens.'''\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "def OHStokenize(text):\n",
    "    '''Tokenize & stem. Stems automatically for now.\n",
    "    Leaving \"stemmer\" out of function call, so it works with TfidfVectorizer'''\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "###########################################################################\n",
    "# tokenization code\n",
    "\n",
    "def seperatePunct(incomingString):\n",
    "    outstr = ''\n",
    "    characters = set(['!','@','#','$',\"%\",\"^\",\"&\",\"*\",\":\",\"\\\\\",\n",
    "                  \"(\",\")\",\"+\",\"=\",\"?\",\"\\'\",\"\\\"\",\";\",\"/\",\n",
    "                  \"{\",\"}\",\"[\",\"]\",\"<\",\">\",\"~\",\"`\",\"|\"])\n",
    "\n",
    "    for char in incomingString:\n",
    "        if char in characters:\n",
    "            outstr = outstr + ' ' + char + ' '\n",
    "        else:\n",
    "            outstr = outstr + char\n",
    "\n",
    "    return outstr\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "     return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def text_cleaner(wordList):\n",
    "    '''\n",
    "    INPUT: List of words to be tokenized\n",
    "    OUTPUT: List of tokenized words\n",
    "    '''\n",
    "\n",
    "    tokenziedList = []\n",
    "\n",
    "    for word in wordList:\n",
    "\n",
    "        #remove these substrings from the word\n",
    "        word = word.replace('[deleted]','')\n",
    "        word = word.replace('&gt','')\n",
    "\n",
    "        #if link, replace with linktag\n",
    "        if 'http' in word:\n",
    "            tokenziedList.append('LINK_TAG')\n",
    "            continue\n",
    "\n",
    "        #if reference to subreddit, replace with reddittag\n",
    "        if '/r/' in word:\n",
    "            tokenziedList.append('SUBREDDIT_TAG')\n",
    "            continue\n",
    "\n",
    "        #if reference to reddit user, replace with usertag\n",
    "        if '/u/' in word:\n",
    "            tokenziedList.append('USER_TAG')\n",
    "            continue\n",
    "\n",
    "        #if reference to twitter user, replace with usertag\n",
    "        if '@' in word:\n",
    "            tokenziedList.append('USER_TAG')\n",
    "            continue\n",
    "\n",
    "        #if number, replace with numtag\n",
    "        #m8 is a word, 5'10\" and 54-59, 56:48 are numbers\n",
    "        if hasNumbers(word) and not any(char.isalpha() for char in word):\n",
    "            tokenziedList.append('NUM_TAG')\n",
    "            continue\n",
    "\n",
    "        #seperate puncuations and add to tokenizedList\n",
    "        newwords = seperatePunct(word).split(\" \")\n",
    "        tokenziedList.extend(newwords)\n",
    "\n",
    "    return tokenziedList\n",
    "\n",
    "def mytokenize(comment):\n",
    "    '''\n",
    "    Input: takes in a reddit comment as a str or unicode and tokenizes it\n",
    "    Output: a tokenized list\n",
    "    '''\n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    sentenceList = tokenizer.tokenize(comment)\n",
    "    wordList = []\n",
    "    for sentence in sentenceList:\n",
    "        wordList.extend(sentence.split(\" \"))\n",
    "\n",
    "    return text_cleaner(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../../data/labeledRedditComments2.p'\n",
    "cvpath = '../../data/twitter_cross_val.csv'\n",
    "\n",
    "df = pickle.load(open(path, 'rb'))\n",
    "dfcv = pd.read_csv(cvpath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a subset of the data for testing this code\n",
    "randNums = np.random.randint(low=0,high=len(df.index),size=(200,1))\n",
    "rowList = [int(row) for row in randNums]\n",
    "dfsmall = df.ix[rowList,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nf = dfsmall\n",
    "X = nf.body\n",
    "y = nf.label\n",
    "\n",
    "Xcv = dfcv['tweet_text'].values\n",
    "ycv = dfcv['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', decode_error='ignore',\n",
    "                           tokenizer=OHStokenize)\n",
    "\n",
    "\n",
    "# fit & transform comments matrix\n",
    "tfidf_X = vect.fit_transform(X)\n",
    "tfidf_Xcv = vect.transform(Xcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1700)\n",
      "(10000, 1700)\n"
     ]
    }
   ],
   "source": [
    "print tfidf_X.shape\n",
    "print tfidf_Xcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr, nc = tfidf_Xcvd.shape\n",
    "newarray = np.ones(shape=(1,nc))\n",
    "newtfidf_Xcvd = np.vstack((tfidf_Xcvd,newarray))\n",
    "newsparse = sparse.csr_matrix(newtfidf_Xcvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 1700)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncv = np.ones(shape=(1, ))\n",
    "ycvnew = np.concatenate((ycv,ncv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ycvnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_Xcvd = tfidf_Xcv.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tfidf_Xcv.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "xg_cv = xgb.DMatrix(tfidf_Xcv, label=ycv)\n",
    "xg_train = xgb.DMatrix(tfidf_X, label=y)\n",
    "xg_newsparse = xgb.DMatrix(newsparse , label=y)\n",
    "xg_cvd = xgb.DMatrix(tfidf_Xcvd, label=ycv)\n",
    "print xg_train.feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n",
      "1696\n",
      "1700\n",
      "1700\n"
     ]
    }
   ],
   "source": [
    "print xg_train.num_col()\n",
    "print xg_cv.num_col()\n",
    "print xg_cvd.num_col()\n",
    "print xg_newsparse.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':2,\n",
    "             'eta':0.5,\n",
    "             'silent':1,\n",
    "             'objective':'binary:logistic',\n",
    "             'eval_metric':'auc'\n",
    "             }\n",
    "num_round = 5\n",
    "watchlist = [(xg_train, 'train'), (xg_cvd, 'eval')]\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.557143\teval-auc:0.499306\n",
      "[1]\ttrain-auc:0.632473\teval-auc:0.494721\n",
      "[2]\ttrain-auc:0.715275\teval-auc:0.488865\n",
      "[3]\ttrain-auc:0.74478\teval-auc:0.478342\n",
      "[4]\ttrain-auc:0.780549\teval-auc:0.5674\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param,\n",
    "                  xg_train,\n",
    "                  num_round,\n",
    "                  watchlist,\n",
    "                  evals_result=results,\n",
    "                  maximize=False,\n",
    "                  verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval': {'auc': [0.499306, 0.494721, 0.488865, 0.478342, 0.5674]},\n",
       " 'train': {'auc': [0.557143, 0.632473, 0.715275, 0.74478, 0.780549]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramdict = {'max_depth':[3,6],'learning_rate':[0.1,0.2]}\n",
    "\n",
    "gs = GridSearchCV(xgb.XGBClassifier,param_grid=paramdict, scoring='auc',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['max_depth','eta','num_rounds','eval_reslts']\n",
    "df = pd.DataFrame(columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [[3,0.1,100,results],[3,0.1,100,results],[3,0.1,100,results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=data,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>eta</th>\n",
       "      <th>num_rounds</th>\n",
       "      <th>eval_reslts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'train': {u'auc': [0.557143, 0.632473, 0.715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'train': {u'auc': [0.557143, 0.632473, 0.715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'train': {u'auc': [0.557143, 0.632473, 0.715...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  eta  num_rounds  \\\n",
       "0          3  0.1         100   \n",
       "1          3  0.1         100   \n",
       "2          3  0.1         100   \n",
       "\n",
       "                                         eval_reslts  \n",
       "0  {u'train': {u'auc': [0.557143, 0.632473, 0.715...  \n",
       "1  {u'train': {u'auc': [0.557143, 0.632473, 0.715...  \n",
       "2  {u'train': {u'auc': [0.557143, 0.632473, 0.715...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evalSet = zip(tfidf_Xcv,ycv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth = 3,\n",
    "                          n_estimators = 20,\n",
    "                          learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-dc5e7c07a2e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# model.fit(tfidf_X,y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# results = model.evals_result()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mgupta/anaconda2/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    422\u001b[0m             evals = list(\n\u001b[0;32m    423\u001b[0m                 \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m             )\n\u001b[0;32m    426\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mgupta/anaconda2/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((x,))\u001b[0m\n\u001b[0;32m    422\u001b[0m             evals = list(\n\u001b[0;32m    423\u001b[0m                 \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m             )\n\u001b[0;32m    426\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mgupta/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m    142\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classes_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mgupta/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape ()"
     ]
    }
   ],
   "source": [
    "model.fit(tfidf_X,y,eval_set = evalSet, eval_metric = 'auc')\n",
    "# model.fit(tfidf_X,y)\n",
    "\n",
    "# results = model.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
